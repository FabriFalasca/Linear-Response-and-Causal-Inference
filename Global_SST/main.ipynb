{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import ticker\n",
    "from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of SST field with Infomap + causality.\n",
    "\n",
    "We consider the SST field in the CM4 Climate model. \n",
    "\n",
    "Length T: 300 years.\n",
    "\n",
    "Temporal resolution: 1 month\n",
    "\n",
    "Grid resolution: $1^\\circ$ (regular grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/tos_300yrs_1deg_nohl_a_monthly_anomalies_new_land0_filter10yr.nc'\n",
    "\n",
    "climate_variable = 'tos'\n",
    "lon_variable = 'lon'\n",
    "lat_variable = 'lat'\n",
    "rand_sample_k = 1000000\n",
    "rand_sample_eta = 1000000\n",
    "q_k = 0.95\n",
    "q_eta = 1 # ---> no heuristic\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "community_map, single_communities, average_signals, cumulative_signals = community_detection.community_detection(path,climate_variable,lon_variable,lat_variable,\n",
    "                                                                                                                 rand_sample_k,rand_sample_eta,q_k,q_eta)\n",
    "end = time.time()\n",
    "\n",
    "print('Finished in '+str(round(end - start, 2))+' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(community_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/community_map_infomap_no_H.npy',community_map)\n",
    "np.save('./results/single_communities_infomap_no_H.npy',single_communities)\n",
    "np.save('./results/average_signals_infomap_no_H.npy',average_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = './data/tos_300yrs_1deg_nohl_a_monthly_anomalies_new_land0_filter10yr.nc'\n",
    "path = './data/tos_300yrs_1deg_nohl_a_monthly_anomalies_new_land0_filter10yr.nc'\n",
    "\n",
    "climate_variable = 'tos'\n",
    "lon_variable = 'lon'\n",
    "lat_variable = 'lat'\n",
    "rand_sample_k = 1000000\n",
    "rand_sample_eta = 1000000\n",
    "q_k = 0.95\n",
    "q_eta = 0.15 \n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "community_map, single_communities, average_signals, cumulative_signals = community_detection.community_detection(path,climate_variable,lon_variable,lat_variable,\n",
    "                                                                                                                rand_sample_k,rand_sample_eta,q_k,q_eta)\n",
    "end = time.time()\n",
    "\n",
    "print('Finished in '+str(round(end - start, 2))+' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(community_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/community_map_infomap_H.npy',community_map)\n",
    "np.save('./results/single_communities_infomap_H.npy',single_communities)\n",
    "np.save('./results/average_signals_infomap_H.npy',average_signals)\n",
    "#np.save('../results/sst/tropical_pacific/original/q_0p95/cumulative_signals_louvain.npy',cumulative_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze piControl Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load longitudes and latitudes\n",
    "path = './data/tos_300yrs_1deg_nohl_a_monthly_anomalies_new_land0_filter10yr.nc'\n",
    "climate_variable = 'tos'\n",
    "lon_variable = 'lon'\n",
    "lat_variable = 'lat'\n",
    "\n",
    "import utils\n",
    "\n",
    "data = utils.load_data(path,climate_variable)\n",
    "data = utils.masked_array_to_numpy(data)\n",
    "\n",
    "latitudes = utils.load_data(path,lat_variable)\n",
    "latitudes = utils.masked_array_to_numpy(latitudes)\n",
    "\n",
    "longitudes = utils.load_data(path,lon_variable)\n",
    "longitudes = utils.masked_array_to_numpy(longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(data[23].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cmocean as cmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (350448456.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    llcrnrlon=0,urcrnrlon=360,lat_ts=20,resolution='c')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cmocean\n",
    "\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "\n",
    "fig = plt.figure(figsize=(14,11))\n",
    "\n",
    "ax = fig.add_subplot(111)  \n",
    "    \n",
    "map = Basemap(projection='nsper',lon_0=105,lat_0=40.5,\n",
    "        resolution='l')\n",
    "\n",
    "#map = Basemap(projection='merc',llcrnrlat=-80,urcrnrlat=80,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,lat_ts=20,resolution='c')\n",
    "\n",
    "map.drawcoastlines()\n",
    "#map.pcolor(longitudes,latitudes,data[23],cmap=cmocean.cm.balance,vmin=-2.5,vmax=2.5)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "#plt.title('Communities', fontsize = 37)\n",
    "#plt.title('(a)', loc = 'left', fontsize = 37)\n",
    "\n",
    "#fig.savefig('./figures/communities_local_vs_nonlocal.pdf',bbox_inches='tight') # bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map_noH = np.load('./results/community_map_infomap_no_H.npy')\n",
    "single_communities_noH = np.load('./results/single_communities_infomap_no_H.npy')\n",
    "average_signals_noH = np.load('./results/average_signals_infomap_no_H.npy')\n",
    "\n",
    "community_map_H = np.load('./results/community_map_infomap_H.npy')\n",
    "single_communities_H = np.load('./results/single_communities_infomap_H.npy')\n",
    "average_signals_H = np.load('./results/average_signals_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map_H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import shiftgrid\n",
    "\n",
    "fig = plt.figure(figsize=(14,11))\n",
    "\n",
    "ax = fig.add_subplot(211)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "#map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title('Communities', fontsize = 37)\n",
    "plt.title('(a)', loc = 'left', fontsize = 37)\n",
    "\n",
    "ax = fig.add_subplot(212)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,community_map_H,cmap=plt.cm.turbo)\n",
    "\n",
    "\n",
    "# Plot domain id\n",
    "plt.title('Communities (Spatially contiguous)', fontsize = 37)\n",
    "plt.title('(b)', loc = 'left', fontsize = 37)\n",
    "\n",
    "fig.savefig('./figures/communities_local_vs_nonlocal.pdf',bbox_inches='tight') # bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities and signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at all average signals\n",
    "for i in range(len(average_signals_H)):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(18,2))\n",
    "\n",
    "    ax = fig.add_subplot(121)  \n",
    "    \n",
    "    map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "    map.drawcoastlines()\n",
    "    map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "    map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "    map.fillcontinents(color = 'black')\n",
    "\n",
    "    #cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "    map.pcolor(longitudes,latitudes,single_communities_H[i],cmap=plt.cm.prism)\n",
    "    #cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "    #cb.ax.tick_params(labelsize=37)\n",
    "    \n",
    "    # Plot domain id\n",
    "    plt.title('Community '+str(i), fontsize = 19)\n",
    "\n",
    "    \n",
    "    ax = fig.add_subplot(122)  \n",
    "    \n",
    "    plt.plot(average_signals_H[i],\"-k\",linewidth = 2)\n",
    "    plt.xlabel('t [month]',fontsize = 20)\n",
    "    #ax.set_xticks([0,60,120,180,240,300,360,420])\n",
    "    #ax.set_xticklabels(['1980','1985','1990','1995','2000','2005','2010','2015'])\n",
    "    plt.ylabel('',fontsize = 20)\n",
    "    plt.xticks(fontsize = 18)\n",
    "    plt.yticks(fontsize = 18)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze correlograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map = np.load('./results/community_map_infomap_H.npy')\n",
    "single_communities = np.load('./results/single_communities_infomap_H.npy')\n",
    "average_signals = np.load('./results/average_signals_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_communities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_linear_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import utils_linear_response\n",
    "\n",
    "standardize_signals = utils_linear_response.remove_mean(average_signals)\n",
    "standardize_signals = utils_linear_response.standardize(standardize_signals)\n",
    "\n",
    "correlograms = []\n",
    "tau_range = 3000\n",
    "\n",
    "for i in range(len(standardize_signals)):\n",
    "\n",
    "    correlograms.append(utils.get_correlogram(standardize_signals[i],standardize_signals[i],tau_range))\n",
    "    \n",
    "correlograms = np.array(correlograms)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at all average signals\n",
    "for i in range(len(average_signals)):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,2))\n",
    "\n",
    "    ax = fig.add_subplot(121)  \n",
    "    \n",
    "    map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "    map.drawcoastlines()\n",
    "    map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "    map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "    map.fillcontinents(color = 'black')\n",
    "\n",
    "        #cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "    map.pcolor(longitudes,latitudes,single_communities[i],cmap=plt.cm.prism)\n",
    "    #cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "    #cb.ax.tick_params(labelsize=37)\n",
    "    \n",
    "    # Plot domain id\n",
    "    plt.title('Community '+str(i), fontsize = 19)\n",
    "\n",
    "    \n",
    "    ax = fig.add_subplot(122)  \n",
    "    \n",
    "    #plt.plot(average_signals[i],\"-k\",linewidth = 2)\n",
    "    plt.plot(correlograms[i,tau_range:,0],correlograms[i,tau_range:,1],'-',linewidth = 2,markersize = 10)\n",
    "    plt.xlabel('t [month]',fontsize = 20)\n",
    "    #ax.set_xticks([0,60,120,180,240,300,360,420])\n",
    "    #ax.set_xticklabels(['1980','1985','1990','1995','2000','2005','2010','2015'])\n",
    "    plt.ylabel('Autocorrelation',fontsize = 16)\n",
    "    plt.xticks(fontsize = 18)\n",
    "    plt.yticks(fontsize = 18)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A look at the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map = np.load('./results/community_map_infomap_H.npy')\n",
    "single_communities = np.load('./results/single_communities_infomap_H.npy')\n",
    "average_signals = np.load('./results/average_signals_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: remove mean and standard deviation\n",
    "normed_signals = average_signals.copy()\n",
    "\n",
    "for i in range(len(normed_signals)):\n",
    "    normed_signals[i] = (average_signals[i] - np.mean(average_signals[i]))/np.std(average_signals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,26))\n",
    "\n",
    "bns = 50\n",
    "alpha_b = 1\n",
    "fontsize_ticks = 19\n",
    "fontsize_legend = 10\n",
    "\n",
    "xlim_minus = -4\n",
    "xlim_plus = +4\n",
    "\n",
    "ylim_minus = -.01\n",
    "ylim_plus = +0.8\n",
    "\n",
    "i = 1\n",
    "\n",
    "for i in np.arange(1,len(normed_signals)+1,1):\n",
    "\n",
    "    ax = fig.add_subplot(4,5,i)  \n",
    "\n",
    "    com = i - 1\n",
    "\n",
    "    n, bins, patches = plt.hist(normed_signals[com], bins= bns, alpha = alpha_b, histtype = 'step',\n",
    "                                linewidth = 3,rwidth=1,log = False, label= 'original',density=True)\n",
    "    \n",
    "    mu = np.mean(normed_signals[com])\n",
    "    sigma = np.std(normed_signals[com])\n",
    "    \n",
    "    bins_gaussian = np.linspace(xlim_minus, xlim_plus, num=bns+1)\n",
    "    \n",
    "    plt.plot(bins_gaussian, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "\n",
    "                   np.exp( - (bins_gaussian - mu)**2 / (2 * sigma**2) ),\n",
    "\n",
    "             linewidth=2, color='r')\n",
    "\n",
    "    plt.xlim([xlim_minus,xlim_plus])\n",
    "    plt.ylim([ylim_minus,ylim_plus])\n",
    "    #plt.xlabel('SSTa',fontsize = fontsize_ticks)\n",
    "    plt.title('Mode '+str(com),fontsize = 24)\n",
    "    plt.xticks(fontsize = fontsize_ticks)\n",
    "    plt.yticks(fontsize = fontsize_ticks)\n",
    "    \n",
    "fig.savefig('./figures/distributions_global.pdf',bbox_inches='tight') # bbox_inches='tight'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causality through linear response theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part can (should?) computed on the server Greene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map = np.load('./results/community_map_infomap_H.npy')\n",
    "single_communities = np.load('./results/single_communities_infomap_H.npy')\n",
    "average_signals = np.load('./results/average_signals_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_linear_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = average_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time length\n",
    "n_time = np.shape(signals)[1]\n",
    "# Number of time series\n",
    "n_ts = np.shape(signals)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_linear_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "tau_max = 12 * 10  # ~12 years in monthly resolution\n",
    "standardized = 'yes' # response computed via correlations functions\n",
    "\n",
    "response_matrix_filter_10yrs = utils_linear_response.response(signals,tau_max,standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/response_matrix.npy',response_matrix_filter_10yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Step (a)\n",
    "# Compute the lag 1 autocorrelation\n",
    "\n",
    "# lag-1 autocorrelation\n",
    "print('Computing lag-1 autocorr')\n",
    "phi = utils_linear_response.phi_vector(signals)\n",
    "\n",
    "############################## Step (b)\n",
    "# Compute standard deviations of each time series\n",
    "\n",
    "# sigmas\n",
    "print('Computing sigmas')\n",
    "sigmas = utils_linear_response.sigmas(signals)\n",
    "\n",
    "### Parameters\n",
    "\n",
    "# we compute responses up to a lag tau_max\n",
    "tau_max = 120\n",
    "# we compute correlations\n",
    "standardized = 'yes'\n",
    "\n",
    "s = 3\n",
    "\n",
    "# This correspondes to +/- 3 sigmas\n",
    "\n",
    "s_minus, s_plus = utils_linear_response.compute_quantile_analytical_tau_discrete(signals,phi,sigmas,tau_max,s,standardized='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/analytical_plus_3sigma.npy',s_plus)\n",
    "np.save('./results/analytical_minus_3sigma.npy',s_minus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Fluctuation Dissipation Relationship and Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not filtered\n",
    "response_matrix = np.load('./results/response_matrix.npy')\n",
    "s_plus = np.load('./results/analytical_plus_3sigma.npy')\n",
    "s_minus = np.load('./results/analytical_minus_3sigma.npy')\n",
    "single_communities = np.load('./results/single_communities_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define node_strength with statistical significance\n",
    "# (There are better ways to write this.)\n",
    "\n",
    "def node_strength_significance(response_matrix,conf_bounds_plus,conf_bounds_minus, absolute_value):\n",
    "    \n",
    "    # Inputs\n",
    "    # - response_matrix\n",
    "    # - significance_right_tail: for example the 99th percentile of the ensemble of null models\n",
    "    # - significance_left_tail: for example the 1st percentile of the ensemble of null models\n",
    "    \n",
    "    # Outputs:\n",
    "    # - strengths_j_k: strength of the connection j -> k\n",
    "    # If the original response matrix is n by n, strengths_j_k will be n x (n - 1)\n",
    "    # as it will not consider self links\n",
    "    \n",
    "    time = np.shape(response_matrix)[0]\n",
    "    # number of rows = number of columns = n\n",
    "    n = np.shape(response_matrix)[1]\n",
    "    \n",
    "    # response_matrix_significant: assign zero if not significant\n",
    "    response_matrix_significant = response_matrix.copy()\n",
    "    \n",
    "    # if you are not significant we change you to zero\n",
    "    indices = (response_matrix < conf_bounds_plus) & (response_matrix > conf_bounds_minus)\n",
    "    response_matrix_significant[indices] = 0\n",
    "    \n",
    "    # Strength of link j -> k\n",
    "    strengths_j_k = np.zeros([n,n])\n",
    "    \n",
    "    if absolute_value == 'yes':\n",
    "    \n",
    "        # Response j -> k in absolute value\n",
    "        abs_response_j_k = np.abs(response_matrix_significant[1:])\n",
    "        # Compute strength of j -> k\n",
    "        strengths_j_k = np.transpose(np.sum(abs_response_j_k,axis = 0))\n",
    "    \n",
    "        # When computing strengths we remove the j -> j connection\n",
    "        # remove diagonal\n",
    "        strengths_j_k_off_diagonal = strengths_j_k[~np.eye(strengths_j_k.shape[0],dtype=bool)].reshape(strengths_j_k.shape[0],-1)\n",
    "    \n",
    "        # Strength of node j\n",
    "        strengths_j = np.sum(strengths_j_k_off_diagonal,axis = 1)\n",
    "        \n",
    "    elif absolute_value == 'no':\n",
    "    \n",
    "        # Response j -> k in absolute value\n",
    "        abs_response_j_k = response_matrix_significant[1:]\n",
    "        # Compute strength of j -> k\n",
    "        strengths_j_k = np.transpose(np.sum(abs_response_j_k,axis = 0))\n",
    "    \n",
    "        # When computing strengths we remove the j -> j connection\n",
    "        # remove diagonal\n",
    "        strengths_j_k_off_diagonal = strengths_j_k[~np.eye(strengths_j_k.shape[0],dtype=bool)].reshape(strengths_j_k.shape[0],-1)\n",
    "    \n",
    "        # Strength of node j\n",
    "        strengths_j = np.sum(strengths_j_k_off_diagonal,axis = 1)    \n",
    "    \n",
    "    return strengths_j_k, strengths_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_value = 'yes'\n",
    "#strengths_j_k, strengths_j = node_strength_significance(response_matrix,null_response_high_percentile,null_response_low_percentile,absolute_value)\n",
    "strengths_j_k, strengths_j = node_strength_significance(response_matrix,s_plus,s_minus,absolute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a causal strength map\n",
    "communities_strength_map = single_communities.copy()\n",
    "\n",
    "for i in range(len(single_communities)):\n",
    "    community_strength = strengths_j[i]\n",
    "    communities_strength_map[i] = single_communities[i] * community_strength\n",
    "    \n",
    "strength_map_tos = np.nansum(communities_strength_map,axis = 0)\n",
    "strength_map_tos[strength_map_tos == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the strength map\n",
    "np.save('./results/strength_map.npy',strength_map_tos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute link maps for the first 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_value = 'no'\n",
    "strengths_j_k, strengths_j = node_strength_significance(response_matrix[0:6],s_plus[0:6],s_minus[0:6],absolute_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load longitudes and latitudes\n",
    "path = '/Users/fabrizio/Dropbox/Science_and_Co/POSTDOC/Analysis/Analysis/Causality_framework/model/dimensionality_reduction/Data/SST/Global/model_300years/highpass/tos_300yrs_1deg_nohl_a_monthly_anomalies_new_land0_filter10yr.nc'\n",
    "\n",
    "climate_variable = 'tos'\n",
    "lon_variable = 'lon'\n",
    "lat_variable = 'lat'\n",
    "\n",
    "import utils\n",
    "\n",
    "data = utils.load_data(path,climate_variable)\n",
    "data = utils.masked_array_to_numpy(data)\n",
    "\n",
    "latitudes = utils.load_data(path,'lat')\n",
    "latitudes = utils.masked_array_to_numpy(latitudes)\n",
    "\n",
    "longitudes = utils.load_data(path,'lon')\n",
    "longitudes = utils.masked_array_to_numpy(longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print causal strength maps\n",
    "\n",
    "strength_ENSO = single_communities.copy()\n",
    "enso_index = 0\n",
    "\n",
    "strength_IO = single_communities.copy()\n",
    "io_index = 1\n",
    "\n",
    "strength_TA_S = single_communities.copy()\n",
    "ta_s_index = 2\n",
    "\n",
    "strength_TA_N = single_communities.copy()\n",
    "ta_n_index = 4\n",
    "\n",
    "\n",
    "for k in range(len(single_communities)): \n",
    "    # enso\n",
    "    strength_ENSO[k] = single_communities[k] * strengths_j_k[enso_index,k]\n",
    "    # io\n",
    "    strength_IO[k] = single_communities[k] * strengths_j_k[io_index,k]\n",
    "    # ta_s\n",
    "    strength_TA_S[k] = single_communities[k] * strengths_j_k[ta_s_index,k]\n",
    "    # ta_n\n",
    "    strength_TA_N[k] = single_communities[k] * strengths_j_k[ta_n_index,k]\n",
    "    \n",
    "# remove your self\n",
    "strength_ENSO = np.delete(strength_ENSO,enso_index,axis=0)\n",
    "strength_IO = np.delete(strength_IO,io_index,axis=0)\n",
    "strength_TA_S = np.delete(strength_TA_S,ta_s_index,axis=0)\n",
    "strength_TA_N = np.delete(strength_TA_N,ta_n_index,axis=0)\n",
    "    \n",
    "strength_map_ENSO = np.nansum(strength_ENSO,axis = 0)\n",
    "strength_map_IO = np.nansum(strength_IO,axis = 0)\n",
    "strength_map_TA_S = np.nansum(strength_TA_S,axis = 0)\n",
    "strength_map_TA_N = np.nansum(strength_TA_N,axis = 0)\n",
    "#strength_map_ENSO[strength_map_ENSO == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a mask\n",
    "mask = data.copy()\n",
    "mask = np.std(data,axis = 0)\n",
    "mask[mask == 0.] = np.nan\n",
    "mask[~np.isnan(mask)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_map_tos = strength_map_tos+mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(strength_map_tos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_map_ENSO = strength_map_ENSO + mask\n",
    "strength_map_IO = strength_map_IO + mask\n",
    "strength_map_TA_S = strength_map_TA_S + mask\n",
    "strength_map_TA_N = strength_map_TA_N + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/link_map_ENSO.npy',strength_map_ENSO)\n",
    "np.save('./results/link_map_IO.npy',strength_map_IO)\n",
    "np.save('./results/link_map_TA_S.npy',strength_map_TA_S)\n",
    "np.save('./results/link_map_TA_N.npy',strength_map_TA_N)\n",
    "#np.save('./results/strength_map.npy',strength_map_tos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot communities and causal strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_map_noH = np.load('./results/community_map_infomap_no_H.npy')\n",
    "single_communities_noH = np.load('./results/single_communities_infomap_no_H.npy')\n",
    "average_signals_noH = np.load('./results/average_signals_infomap_no_H.npy')\n",
    "\n",
    "community_map_H = np.load('./results/community_map_infomap_H.npy')\n",
    "single_communities_H = np.load('./results/single_communities_infomap_H.npy')\n",
    "average_signals_H = np.load('./results/average_signals_infomap_H.npy')\n",
    "\n",
    "strength = np.load('./results/strength_map.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import shiftgrid\n",
    "\n",
    "fig = plt.figure(figsize=(14,22))\n",
    "\n",
    "fontsize_title = 37\n",
    "fontsize_coord = 12\n",
    "labelsize_cb = 12\n",
    "vmin_ENSO = -6.1\n",
    "vmax_ENSO = +6.1\n",
    "vmin_IO = -1.5\n",
    "vmax_IO = +1.5\n",
    "vmin_TAs = -2.2\n",
    "vmax_TAs = +2.2\n",
    "pad = 0.12\n",
    "j_size = 19\n",
    "\n",
    "ax = fig.add_subplot(311)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "#map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title('Communities', fontsize = fontsize_title)\n",
    "plt.title('(a)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "ax = fig.add_subplot(312)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,community_map_H,cmap=plt.cm.turbo)\n",
    "\n",
    "\n",
    "# Plot domain id\n",
    "plt.title('Communities (Spatially contiguous)', fontsize = fontsize_title)\n",
    "plt.title('(b)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "ax = fig.add_subplot(313)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,strength,cmap=plt.cm.viridis,vmin = 0,vmax = 15)\n",
    "cb=plt.colorbar(location='bottom',aspect=30,pad=0.1)\n",
    "cb.ax.tick_params(labelsize=28)\n",
    "\n",
    "\n",
    "# Plot domain id\n",
    "plt.title(r'$\\mathcal{D}_{j}$ (ENSO = 40.2)', fontsize = fontsize_title)\n",
    "plt.title('(c)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "plt.subplots_adjust(hspace=-0.4)\n",
    "\n",
    "fig.savefig('./figures/communities_and_strengths.pdf',bbox_inches='tight') # bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strengths and link maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_communities_H = np.load('./results/single_communities_infomap_H.npy')\n",
    "\n",
    "strength = np.load('./results/strength_map.npy')\n",
    "\n",
    "links_ENSO_GFDL = np.load('./results/link_map_ENSO.npy')\n",
    "links_IO_GFDL = np.load('./results/link_map_IO.npy')\n",
    "links_TA_S_GFDL = np.load('./results/link_map_TA_S.npy')\n",
    "links_TA_N_GFDL = np.load('./results/link_map_TA_N.npy')\n",
    "\n",
    "single_communities_H = np.load('./results/single_communities_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal link maps one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import shiftgrid\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "fontsize_title = 14\n",
    "fontsize_coord = 12\n",
    "labelsize_cb = 12\n",
    "\n",
    "vmin_ENSO = -2.5\n",
    "vmax_ENSO = +2.5\n",
    "\n",
    "vmin_IO = -0.8\n",
    "vmax_IO = +0.8\n",
    "\n",
    "vmin_TAs = -0.6\n",
    "vmax_TAs = +0.6\n",
    "\n",
    "vmin_TAn = -0.6\n",
    "vmax_TAn = +0.6\n",
    "\n",
    "pad = 0.12\n",
    "j_size = 19\n",
    "\n",
    "\n",
    "########################### ENSO causal links\n",
    "ax = fig.add_subplot(221)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,links_ENSO_GFDL,cmap=cmocean.cm.balance,vmin = vmin_ENSO, vmax = vmax_ENSO)\n",
    "cb=plt.colorbar(location='bottom',aspect=30,pad=pad)\n",
    "cb.ax.tick_params(labelsize=labelsize_cb)\n",
    "plt.text(230, -12, 'j', c = 'k', fontsize=j_size)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title(r'$\\mathcal{D}_{j \\rightarrow k}$; j = ENSO', fontsize = fontsize_title)\n",
    "plt.title('(a)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "########################### IO causal links\n",
    "ax = fig.add_subplot(222)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,links_IO_GFDL,cmap=cmocean.cm.balance,vmin = vmin_IO, vmax = vmax_IO)\n",
    "cb=plt.colorbar(location='bottom',aspect=30,pad=pad)\n",
    "cb.ax.tick_params(labelsize=labelsize_cb)\n",
    "plt.text(64, -6, 'j', c = 'k', fontsize=j_size)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title(r'$\\mathcal{D}_{j \\rightarrow k}$; j = Indian Oc.', fontsize = fontsize_title)\n",
    "plt.title('(b)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "########################### TA_s causal links abs\n",
    "ax = fig.add_subplot(223)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,links_TA_S_GFDL,cmap=cmocean.cm.balance,vmin = vmin_TAs, vmax = vmax_TAs)\n",
    "cb=plt.colorbar(location='bottom',aspect=30,pad=pad)\n",
    "cb.ax.tick_params(labelsize=labelsize_cb)\n",
    "plt.text(340, -16, 'j', c = 'k', fontsize=j_size)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title(r'$\\mathcal{D}_{j \\rightarrow k}$; j = S. Trop. Atl.', fontsize = fontsize_title)\n",
    "plt.title('(c)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "########################### TA_s causal links abs\n",
    "ax = fig.add_subplot(224)  \n",
    "    \n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = fontsize_coord,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "map.pcolor(longitudes,latitudes,links_TA_N_GFDL,cmap=cmocean.cm.balance,vmin = vmin_TAn, vmax = vmax_TAn)\n",
    "cb=plt.colorbar(location='bottom',aspect=30,pad=pad)\n",
    "cb.ax.tick_params(labelsize=labelsize_cb)\n",
    "plt.text(320, 8, 'j', c = 'k', fontsize=j_size)\n",
    "#map.pcolor(longitudes+100,latitudes,community_map_noH,cmap=plt.cm.turbo)\n",
    "#cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "#cb.ax.tick_params(labelsize=37)\n",
    "plt.title(r'$\\mathcal{D}_{j \\rightarrow k}$; j = N. Trop. Atl.', fontsize = fontsize_title)\n",
    "plt.title('(d)', loc = 'left', fontsize = fontsize_title)\n",
    "\n",
    "fig.savefig('./figures/causal_link_maps_first_6months.pdf',bbox_inches='tight') # bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus on single domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(single_communities)):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,2))\n",
    "\n",
    "    #j = 3\n",
    "\n",
    "    ax = fig.add_subplot(121)  \n",
    "\n",
    "    map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "    map.drawcoastlines()\n",
    "    map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "    map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "    map.fillcontinents(color = 'black')\n",
    "\n",
    "\n",
    "        #cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "    map.pcolor(longitudes,latitudes,single_communities[j],cmap=plt.cm.prism)\n",
    "    #cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "    #cb.ax.tick_params(labelsize=37)\n",
    "\n",
    "    # Plot domain id\n",
    "    plt.title('Community '+str(j), fontsize = 19)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider linkages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not filtered\n",
    "response_matrix = np.load('./results/response_matrix.npy')\n",
    "\n",
    "s_plus = np.load('./results/analytical_plus_3sigma.npy')\n",
    "s_minus = np.load('./results/analytical_minus_3sigma.npy')\n",
    "\n",
    "single_communities = np.load('./results/single_communities_infomap_H.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community j = 0 ---> k (Around Niño)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check who is Niño 3.4 leading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the causal link j -> k where \n",
    "# k = 12 is the Gulf Of Mexico \n",
    "# So we are checking the relationship between every other domain and the GoM\n",
    "\n",
    "j = 0\n",
    "\n",
    "# Let's look at all average signals\n",
    "for k in range(len(single_communities)):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "    ax = fig.add_subplot(211)  \n",
    "    \n",
    "    map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "    map.drawcoastlines()\n",
    "    #map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "    #map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "    map.fillcontinents(color = 'black')\n",
    "\n",
    "    #cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "    map.pcolor(longitudes,latitudes,single_communities[j],cmap = plt.cm.bwr_r,label='#5')\n",
    "    map.pcolor(longitudes,latitudes,single_communities[k],cmap=plt.cm.bwr,label='#'+str(k))\n",
    "    #cb=plt.colorbar(location='bottom',aspect=20,pad=0.08)\n",
    "    #cb.ax.tick_params(labelsize=37)\n",
    "    \n",
    "    # Plot domain id\n",
    "    plt.title('$x^{(j)}$'+ r'$\\rightarrow$ '+'$x^{(k)}$', fontsize = 24)\n",
    "\n",
    "    ax = fig.add_subplot(212)  \n",
    "    \n",
    "    plt.plot(response_matrix[:,k,j],'.-',label = 'Response',linewidth = 1,markersize = 6)\n",
    "    plt.plot(s_plus[:,k,j],'-.',linewidth = 3,label='$+ 3 \\sigma$')\n",
    "    plt.plot(s_minus[:,k,j],'-.',linewidth = 3,label='$- 3 \\sigma$')\n",
    "    #plt.plot(null_response_99p9_percentile[:,k,j],'-.',label = '$q = 1 - 10^{-5}$',linewidth = 3)\n",
    "    #plt.plot(null_response_0p1_percentile[:,k,j],'-.',label = '$q = 10^{-5}$',linewidth = 3)\n",
    "    #plt.plot(null_response_99_percentile[:,k,j],'-.',label = '99th percentile',color = 'tab:red',linewidth = 3)\n",
    "    #plt.plot(null_response_1_percentile[:,k,j],'-.',label = '1st percentile',color = 'tab:red',linewidth = 3)\n",
    "\n",
    "    plt.legend(loc = 'upper right',fontsize = 16)\n",
    "\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    #ax.set_xticks([0,5,10,15,20])\n",
    "    #ax.set_xticklabels(['0','5','10','15','20'])\n",
    "\n",
    "    plt.xlabel('lag (1 month)',fontsize = 20)\n",
    "    plt.title('Response',fontsize = 20)\n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.15, hspace=0)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #fig.savefig('./figures/Infomap/q0p95/no_heuristics/ElNino_connections/ElNino_Linkages_'+str(k)+'.eps',bbox_inches='tight') # bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "ax = plt.subplot(321)\n",
    "\n",
    "j = 2\n",
    "k = 0\n",
    "\n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "#map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "#map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "#cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "map.pcolor(longitudes,latitudes,single_communities[j],cmap = plt.cm.bwr_r,label='#5')\n",
    "map.pcolor(longitudes,latitudes,single_communities[k],cmap=plt.cm.bwr,label='#'+str(k))\n",
    "\n",
    "plt.text(220,-8,'$x$',fontsize=24,color = 'w')\n",
    "plt.text(340,-15,'$y$',fontsize=24,c = 'k')\n",
    "\n",
    "plt.title('', loc = 'left', fontsize=16)\n",
    "\n",
    "ax = plt.subplot(322)\n",
    "\n",
    "j = 1\n",
    "k = 0\n",
    "\n",
    "map = Basemap(projection='cyl',\n",
    "            llcrnrlat=-60,urcrnrlat=60,\\\n",
    "              llcrnrlon=0,urcrnrlon=360)\n",
    "\n",
    "map.drawcoastlines()\n",
    "#map.drawparallels(np.arange(-60.,75,30),  labels=[1,0,0,0], fontsize = 28,linewidth=0.001)\n",
    "#map.drawmeridians(np.arange(0.,360.,90.), labels=[0,0,0,1], fontsize = 28,linewidth=0.001)\n",
    "map.fillcontinents(color = 'black')\n",
    "\n",
    "#cmap=discrete_cmap(50,base_cmap=plt.cm.jet)\n",
    "map.pcolor(longitudes,latitudes,single_communities[j],cmap = plt.cm.bwr_r,label='#5')\n",
    "map.pcolor(longitudes,latitudes,single_communities[k],cmap=plt.cm.bwr,label='#'+str(k))\n",
    "\n",
    "plt.text(220,-8,'$x$',fontsize=24,color = 'w')\n",
    "plt.text(70,-15,'$z$',fontsize=24,c = 'k')\n",
    "\n",
    "plt.title('', loc = 'left', fontsize=16)\n",
    "\n",
    "ax = plt.subplot(323)\n",
    "\n",
    "j = 0\n",
    "k = 2\n",
    "\n",
    "plt.plot(response_matrix[:,k,j],'.-',color = 'tab:blue',linewidth = 1,markersize = 5)\n",
    "# Analytical\n",
    "plt.plot(s_plus[:,k,j],'-.', color = 'k',linewidth = 2,markersize = 20)#\n",
    "plt.plot(s_minus[:,k,j],'-.',label = 'Confidence Bounds',color = 'k',linewidth = 2,markersize = 20)\n",
    "\n",
    "plt.legend(fontsize = 14)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize = 16)\n",
    "#ax.set_xticks([0,5,10,15,20])\n",
    "#ax.set_xticklabels(['0','5','10','15','20'])\n",
    "\n",
    "#plt.ylim([-0.25,0.6])\n",
    "\n",
    "#plt.xlabel('lag ' + r'$\\tau$',fontsize = 20)\n",
    "#plt.ylim([-0.2,0.6])\n",
    "        \n",
    "plt.title('$x$' + ' --> ' + '$y$', c = 'k', fontsize=19)\n",
    "plt.title('(a)', loc = 'left', fontsize=16)\n",
    "\n",
    "ax = plt.subplot(324)\n",
    "\n",
    "j = 0\n",
    "k = 1\n",
    "\n",
    "plt.plot(response_matrix[:,k,j],'.-',color = 'tab:blue',linewidth = 1,markersize = 5)\n",
    "# Analytical\n",
    "plt.plot(s_plus[:,k,j],'-.', color = 'k',linewidth = 2,markersize = 20)#\n",
    "plt.plot(s_minus[:,k,j],'-.',label = 'Confidence Bounds',color = 'k',linewidth = 2,markersize = 20)\n",
    "\n",
    "#plt.legend(fontsize = 14)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize = 16)\n",
    "#ax.set_xticks([0,5,10,15,20])\n",
    "#ax.set_xticklabels(['0','5','10','15','20'])\n",
    "\n",
    "#plt.ylim([-0.25,0.6])\n",
    "\n",
    "#plt.xlabel('lag ' + r'$\\tau$',fontsize = 20)\n",
    "        \n",
    "plt.title('$x$' + ' --> ' + '$z$', c = 'k', fontsize=19)\n",
    "plt.title('(b)', loc = 'left', fontsize=16)\n",
    "\n",
    "\n",
    "j = 2\n",
    "k = 0\n",
    "\n",
    "ax = plt.subplot(325)\n",
    "plt.plot(response_matrix[:,k,j],'.-',color = 'tab:blue',linewidth = 1,markersize = 5)\n",
    "\n",
    "# Analytical\n",
    "plt.plot(s_plus[:,k,j],'-.', color = 'k',linewidth = 2,markersize = 20)#\n",
    "plt.plot(s_minus[:,k,j],'-.',label = 'Confidence Bounds',color = 'k',linewidth = 2,markersize = 20)\n",
    "\n",
    "#plt.legend(fontsize = 18)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "#plt.ylim([-0.25,0.6])\n",
    "\n",
    "plt.xlabel('lag ' + r'$\\tau$' + ' (1 month)',fontsize = 16)\n",
    "        \n",
    "plt.title('$y$' + ' --> ' + '$x$', fontsize=19)\n",
    "plt.title('(c)', loc = 'left', fontsize=16)\n",
    "\n",
    "j = 1\n",
    "k = 0\n",
    "\n",
    "ax = plt.subplot(326)\n",
    "plt.plot(response_matrix[:,k,j],'.-',color = 'tab:blue',linewidth = 1,markersize = 5)\n",
    "\n",
    "# Analytical\n",
    "plt.plot(s_plus[:,k,j],'-.', color = 'k',linewidth = 2,markersize = 20)#\n",
    "plt.plot(s_minus[:,k,j],'-.',label = 'Confidence Bounds',color = 'k',linewidth = 2,markersize = 20)\n",
    "\n",
    "#plt.legend(fontsize = 18)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "#plt.ylim([-0.25,0.6])\n",
    "\n",
    "plt.xlabel('lag ' + r'$\\tau$' + ' (1 month)',fontsize = 16)\n",
    "        \n",
    "plt.title('$z$' + ' --> ' + '$x$', fontsize=19)\n",
    "plt.title('(d)', loc = 'left', fontsize=16)\n",
    "\n",
    "fig.savefig('./figures/ENSO_AtlanticNino_IO.eps',bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
